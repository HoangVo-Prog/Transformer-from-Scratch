# Transformer-from-Scratch (in Pytorch)

# Why I do this project:
- Persue an deep-understanding knowledge about DL
- Reach to the implemention of other Transformer' versions
- Inspired by the Mislav Jurić blog, of how effort he/se putted in the project
The origin post of him is here: https://www.mislavjuric.com/transformer-from-scratch-in-pytorch/


# My Goals: 
- Ensure the model having nearly 1 loss on my dataset
- Ensure that the model trained worked better on the baseline (which was an untrained trainsformer)

# What is the rules for the project:
- R1: I was allowed to [read original paper](https://arxiv.org/pdf/1706.03762) and start writing code from there. If I got stucked, I was allowed to get to R2
- R2: I was allowed to consult blog posts and/or articles containing explanations for the things I didn’t understand. If it contained code by any chance, I wouldn’t look at it. If I got stuck here as well, I was allowed to go to R3.
- R3: I was allowed to ask questions on particular things I didn’t understand or about a particular bug in my code, after I tried to solve the misunderstanding or the bug by myself for some reasonable amount of time.
- R4: I was allowed to look at existing Transformer implementations. Also, I was allowed to copy/paste certain parts of code

